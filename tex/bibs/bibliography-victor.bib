@inproceedings{NIPS2017_3f5ee243,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  editor = {Guyon, I and Luxburg, U Von and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  keywords = {DL}
}

@article{Abarbanel2018,
  title = {Machine Learning: Deepest Learning as Statistical Data Assimilation Problems},
  author = {Abarbanel, Henry D. I. and Rozdeba, Paul J. and Shirman, Sasha},
  date = {2018-08},
  journaltitle = {Neural Computation},
  volume = {30},
  number = {8},
  eprint = {29894650},
  eprinttype = {pmid},
  pages = {2025--2055},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01094},
  url = {https://direct.mit.edu/neco/article/30/8/2025-2055/8382},
  abstract = {We formulate an equivalence between machine learning and the formulation of statistical data assimilation as used widely in physical and biological sciences. The correspondence is that layer number in a feedforward artificial network setting is the analog of time in the data assimilation setting. This connection has been noted in the machine learning literature. We add a perspective that expands on how methods from statistical physics and aspects of Lagrangian and Hamiltonian dynamics play a role in how networks can be trained and designed. Within the discussion of this equivalence, we show that adding more layers (making the network deeper) is analogous to adding temporal resolution in a data assimilation framework. Extending this equivalence to recurrent networks is also discussed.},
  keywords = {data-assimilation,DL}
}

@article{Barnosky2012,
  title = {Approaching a State Shift in {{Earth}}'s Biosphere},
  author = {Barnosky, Anthony D. and Hadly, Elizabeth A. and Bascompte, Jordi and Berlow, Eric L. and Brown, James H. and Fortelius, Mikael and Getz, Wayne M. and Harte, John and Hastings, Alan and Marquet, Pablo A. and Martinez, Neo D. and Mooers, Arne and Roopnarine, Peter and Vermeij, Geerat and Williams, John W. and Gillespie, Rosemary and Kitzes, Justin and Marshall, Charles and Matzke, Nicholas and Mindell, David P. and Revilla, Eloy and Smith, Adam B.},
  date = {2012},
  journaltitle = {Nature},
  volume = {486},
  number = {7401},
  eprint = {22678279},
  eprinttype = {pmid},
  pages = {52--58},
  publisher = {{Nature Publishing Group}},
  issn = {00280836},
  doi = {10.1038/nature11018},
  url = {http://dx.doi.org/10.1038/nature11018},
  abstract = {Localized ecological systems are known to shift abruptly and irreversibly from one state to another when they are forced across critical thresholds. Here we review evidence that the global ecosystem as a whole can react in the same way and is approaching a planetary-scale critical transition as a result of human influence. The plausibility of a planetary-scale ‘tipping point’ highlights the need to improve biological forecasting by detecting early warning signs of critical transitions on global as well as local scales, and by detecting feedbacks that promote such transitions. It is also necessary to address root causes of how humans are forcing biological changes.},
  isbn = {1476-4687 (Electronic)\textbackslash r0028-0836 (Linking)},
  keywords = {biodiversity,climatechangebiodiversity,tippingpoints}
}

@article{Bocquet2019,
  title = {Data Assimilation as a Learning Tool to Infer Ordinary Differential Equation Representations of Dynamical Models},
  author = {Bocquet, Marc and Brajard, Julien and Carrassi, Alberto and Bertino, Laurent},
  date = {2019-07-10},
  journaltitle = {Nonlinear Processes in Geophysics},
  volume = {26},
  number = {3},
  pages = {143--162},
  issn = {1607-7946},
  doi = {10.5194/npg-26-143-2019},
  url = {https://npg.copernicus.org/articles/26/143/2019/},
  abstract = {Abstract. Recent progress in machine learning has shown how to forecast and, to some extent, learn the dynamics of a model from its output, resorting in particular to neural networks and deep learning techniques. We will show how the same goal can be directly achieved using data assimilation techniques without leveraging on machine learning software libraries, with a view to high-dimensional models. The dynamics of a model are learned from its observation and an ordinary differential equation (ODE) representation of this model is inferred using a recursive nonlinear regression. Because the method is embedded in a Bayesian data assimilation framework, it can learn from partial and noisy observations of a state trajectory of the physical model. Moreover, a space-wise local representation of the ODE system is introduced and is key to coping with high-dimensional models. It has recently been suggested that neural network architectures could be interpreted as dynamical systems. Reciprocally, we show that our ODE representations are reminiscent of deep learning architectures. Furthermore, numerical analysis considerations of stability shed light on the assets and limitations of the method. The method is illustrated on several chaotic discrete and continuous models of various dimensions, with or without noisy observations, with the goal of identifying or improving the model dynamics, building a surrogate or reduced model, or producing forecasts solely from observations of the physical model.},
  keywords = {inference,parameter-estimation},
}


@article{Brajard2021,
  title = {Combining Data Assimilation and Machine Learning to Infer Unresolved Scale Parametrization},
  author = {Brajard, Julien and Carrassi, Alberto and Bocquet, Marc and Bertino, Laurent},
  date = {2021},
  journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {379},
  number = {2194},
  eprint = {33583267},
  eprinttype = {pmid},
  issn = {1364503X},
  doi = {10.1098/rsta.2020.0086},
  abstract = {In recent years, machine learning (ML) has been proposed to devise data-driven parametrizations of unresolved processes in dynamical numerical models. In most cases, the ML training leverages high-resolution simulations to provide a dense, noiseless target state. Our goal is to go beyond the use of high-resolution simulations and train ML-based parametrization using direct data, in the realistic scenario of noisy and sparse observations. The algorithm proposed in this work is a two-step process. First, data assimilation (DA) techniques are applied to estimate the full state of the system from a truncated model. The unresolved part of the truncated model is viewed as a model error in the DA system. In a second step, ML is used to emulate the unresolved part, a predictor of model error given the state of the system. Finally, the ML-based parametrization model is added to the physical core truncated model to produce a hybrid model. The DA component of the proposed method relies on an ensemble Kalman filter while the ML parametrization is represented by a neural network. The approach is applied to the two-scale Lorenz model and to MAOOAM, a reduced-order coupled ocean-atmosphere model. We show that in both cases, the hybrid model yields forecasts with better skill than the truncated model. Moreover, the attractor of the system is significantly better represented by the hybrid model than by the truncated model. This article is part of the theme issue 'Machine learning for weather and climate modelling'.},
  keywords = {climate,DL,machinelearning,sciml},
}

@article{Carrassi2018,
  title = {Data Assimilation in the Geosciences: {{An}} Overview of Methods, Issues, and Perspectives},
  author = {Carrassi, Alberto and Bocquet, Marc and Bertino, Laurent and Evensen, Geir},
  date = {2018-09-09},
  journaltitle = {WIREs Climate Change},
  volume = {9},
  number = {5},
  eprint = {1709.02798},
  eprinttype = {arxiv},
  pages = {1--50},
  issn = {1757-7780},
  doi = {10.1002/wcc.535},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/wcc.535},
  abstract = {We commonly refer to state estimation theory in geosciences as data assimilation (DA). This term encompasses the entire sequence of operations that, starting from the observations of a system, and from additional statistical and dynamical information (such as a dynamical evolution model), provides an estimate of its state. DA is standard practice in numerical weather prediction, but its application is becoming widespread in many other areas of climate, atmosphere, ocean, and environment modeling; in all circumstances where one intends to estimate the state of a large dynamical system based on limited information. While the complexity of DA, and of the methods thereof, stands on its interdisciplinary nature across statistics, dynamical systems, and numerical optimization, when applied to geosciences, an additional difficulty arises by the continually increasing sophistication of the environmental models. Thus, in spite of DA being nowadays ubiquitous in geosciences, it has so far remained a topic mostly reserved to experts. We aim this overview article at geoscientists with a background in mathematical and physical modeling, who are interested in the rapid development of DA and its growing domains of application in environmental science, but so far have not delved into its conceptual and methodological complexities. This article is categorized under: Climate Models and Modeling {$>$} Knowledge Generation with Models.},
  keywords = {data-assimilation},
}

@article{Curtsdotter2019,
  title = {Ecosystem Function in Predator–Prey Food Webs—Confronting Dynamic Models with Empirical Data},
  author = {Curtsdotter, Alva and Banks, H. Thomas and Banks, John E. and Jonsson, Mattias and Jonsson, Tomas and Laubmeier, Amanda N. and Traugott, Michael and Bommarco, Riccardo},
  editor = {Stouffer, Daniel},
  date = {2019-02-07},
  journaltitle = {Journal of Animal Ecology},
  volume = {88},
  number = {2},
  eprint = {30079547},
  eprinttype = {pmid},
  pages = {196--210},
  issn = {0021-8790},
  doi = {10.1111/1365-2656.12892},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1365-2656.12892},
  abstract = {Most ecosystem functions and related services involve species interactions across trophic levels, for example, pollination and biological pest control. Despite this, our understanding of ecosystem function in multitrophic communities is poor, and research has been limited to either manipulation in small communities or statistical descriptions in larger ones. Recent advances in food web ecology may allow us to overcome the trade-off between mechanistic insight and ecological realism. Molecular tools now simplify the detection of feeding interactions, and trait-based approaches allow the application of dynamic food web models to real ecosystems. We performed the first test of an allometric food web model's ability to replicate temporally nonaggregated abundance data from the field and to provide mechanistic insight into the function of predation. We aimed to reproduce and explore the drivers of the population dynamics of the aphid herbivore Rhopalosiphum padi observed in ten Swedish barley fields. We used a dynamic food web model, taking observed interactions and abundances of predators and alternative prey as input data, allowing us to examine the role of predation in aphid population control. The inverse problem methods were used for simultaneous model fit optimization and model parameterization. The model captured {$>$}70\% of the variation in aphid abundance in five of ten fields, supporting the model-embodied hypothesis that body size can be an important determinant of predation in the arthropod community. We further demonstrate how in-depth model analysis can disentangle the likely drivers of function, such as the community's abundance and trait composition. Analysing the variability in model performance revealed knowledge gaps, such as the source of episodic aphid mortality, and general method development needs that, if addressed, would further increase model success and enable stronger inference about ecosystem function. The results demonstrate that confronting dynamic food web models with abundance data from the field is a viable approach to evaluate ecological theory and to aid our understanding of function in real ecosystems. However, to realize the full potential of food web models, in ecosystem function research and beyond, trait-based parameterization must be refined and extended to include more traits than body size.},
  keywords = {parameter-estimation},
}

@article{Gabor2015,
  title = {Robust and Efficient Parameter Estimation in Dynamic Models of Biological Systems},
  author = {Gábor, Attila and Banga, Julio R.},
  date = {2015-12-29},
  journaltitle = {BMC Systems Biology},
  volume = {9},
  number = {1},
  eprint = {26515482},
  eprinttype = {pmid},
  pages = {74},
  publisher = {{BMC Systems Biology}},
  issn = {1752-0509},
  doi = {10.1186/s12918-015-0219-2},
  url = {http://dx.doi.org/10.1186/s12918-015-0219-2},
  abstract = {Background: Dynamic modelling provides a systematic framework to understand function in biological systems. Parameter estimation in nonlinear dynamic models remains a very challenging inverse problem due to its nonconvexity and ill-conditioning. Associated issues like overfitting and local solutions are usually not properly addressed in the systems biology literature despite their importance. Here we present a method for robust and efficient parameter estimation which uses two main strategies to surmount the aforementioned difficulties: (i) efficient global optimization to deal with nonconvexity, and (ii) proper regularization methods to handle ill-conditioning. In the case of regularization, we present a detailed critical comparison of methods and guidelines for properly tuning them. Further, we show how regularized estimations ensure the best trade-offs between bias and variance, reducing overfitting, and allowing the incorporation of prior knowledge in a systematic way. Results: We illustrate the performance of the presented method with seven case studies of different nature and increasing complexity, considering several scenarios of data availability, measurement noise and prior knowledge. We show how our method ensures improved estimations with faster and more stable convergence. We also show how the calibrated models are more generalizable. Finally, we give a set of simple guidelines to apply this strategy to a wide variety of calibration problems. Conclusions: Here we provide a parameter estimation strategy which combines efficient global optimization with a regularization scheme. This method is able to calibrate dynamic models in an efficient and robust way, effectively fighting overfitting and allowing the incorporation of prior information.},
  isbn = {1291801502},
  keywords = {inference,parameter-estimation}}

@article{Gharamti2017,
  title = {Ensemble Data Assimilation for Ocean Biogeochemical State and Parameter Estimation at Different Sites},
  author = {Gharamti, M.E. and Tjiputra, J. and Bethke, I. and Samuelsen, A. and Skjelvan, I. and Bentsen, M. and Bertino, L.},
  date = {2017-04},
  journaltitle = {Ocean Modelling},
  volume = {112},
  pages = {65--89},
  publisher = {{Elsevier Ltd}},
  issn = {14635003},
  doi = {10.1016/j.ocemod.2017.02.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1463500317300215},
  abstract = {We develop an efficient data assimilation system that aims at quantifying the uncertainties of various biogeochemical states and parameters. We explore the use of four different ensemble estimation techniques for tuning poorly constrained ecosystem parameters using a one-dimensional configuration of the Ocean Biogeochemical General Circulation Model. The schemes are all EnKF-based operating sequentially in time but have different correction equations. The 1D model is used to simulate the biogeochemical cycle at three different stations in mid and high latitudes. We assimilate monthly climatological profiles of nitrate, silicate, phosphate and oxygen in addition to seasonal surface pCO2 data, between 2006 and 2010. We use the data to optimize eleven ecosystem parameters in addition to all state variables of the model, describing the dynamical processes of the water column. Our assimilation results suggest the following: (1) Among all tested schemes, the one-step-ahead smoothing-based ensemble Kalman filter (OSA-EnKF) is robust and the most accurate, providing consistent and reliable state-parameter ensemble realizations. (2) Given the large uncertainties associated with the ecosystem parameters, estimating only the state variables is generally inconclusive and biased. (3) The OSA-EnKF successfully recovers the observed seasonal variability of the ecosystem dynamics at all stations and helps optimizing the parameters, eventually reducing the prediction errors of the nutrients’ concentrations. (4) The estimates of the parameters may have some temporally correlated features and they can also vary spatially between different regions depending on the magnitude of the bias in the observed variables and other factors such as the intensity of the bloom period. We further show that the presented assimilation system has the potential to be used in global models.},
  keywords = {parameter-estimation}
}

@unpublished{Kingma2014,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2014-12-22},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  pages = {1--15},
  url = {http://arxiv.org/abs/1412.6980},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  keywords = {deepsplitting,inference,parameter-estimation,PDE}
}

@article{LeCun2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015-05-27},
  journaltitle = {Nature},
  volume = {521},
  number = {7553},
  eprint = {26017442},
  eprinttype = {pmid},
  pages = {436--444},
  issn = {0028-0836},
  doi = {10.1038/nature14539},
  url = {http://www.nature.com/articles/nature14539},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
}

@article{Rosenbaum2019,
  title = {Estimating {{Parameters From Multiple Time Series}} of {{Population Dynamics Using Bayesian Inference}}},
  author = {Rosenbaum, Benjamin and Raatz, Michael and Weithoff, Guntram and Fussmann, Gregor F. and Gaedke, Ursula},
  date = {2019-01-22},
  journaltitle = {Frontiers in Ecology and Evolution},
  volume = {6},
  issn = {2296-701X},
  doi = {10.3389/fevo.2018.00234},
  url = {https://www.frontiersin.org/article/10.3389/fevo.2018.00234/full},
  abstract = {Empirical time series of interacting entities, e.g., species abundances, are highly useful to study ecological mechanisms. Mathematical models are valuable tools to further elucidate those mechanisms and underlying processes. However, obtaining an agreement between model predictions and experimental observations remains a demanding task. As models always abstract from reality one parameter often summarizes several properties. Parameter measurements are performed in additional experiments independent of the ones delivering the time series. Transferring these parameter values to different settings may result in incorrect parametrizations. On top of that, the properties of organisms and thus the respective parameter values may vary considerably. These issues limit the use of a priori model parametrizations. In this study, we present a method suited for a direct estimation of model parameters and their variability from experimental time series data. We combine numerical simulations of a continuous-time dynamical population model with Bayesian inference, using a hierarchical framework that allows for variability of individual parameters. The method is applied to a comprehensive set of time series from a laboratory predator-prey system that features both steady states and cyclic population dynamics. Our model predictions are able to reproduce both steady states and cyclic dynamics of the data. Additionally to the direct estimates of the parameter values, the Bayesian approach also provides their uncertainties. We found that fitting cyclic population dynamics, which contain more information on the process rates than steady states, yields more precise parameter estimates. We detected significant variability among parameters of different time series and identified the variation in the maximum growth rate of the prey as a source for the transition from steady states to cyclic dynamics. By lending more flexibility to the model, our approach facilitates parametrizations and shows more easily which patterns in time series can be explained also by simple models. Applying Bayesian inference and dynamical population models in conjunction may help to quantify the profound variability in organismal properties in nature.},
  issue = {JAN},
  keywords = {parameter-estimation},
  file = {/Users/victorboussange/Zotero/storage/RBB856N4/fevo-06-00234.pdf}
}

@article{Schartau2017,
  title = {Reviews and Syntheses: Parameter Identification in Marine Planktonic Ecosystem Modelling},
  author = {Schartau, Markus and Wallhead, Philip and Hemmings, John and Löptien, Ulrike and Kriest, Iris and Krishna, Shubham and Ward, Ben A. and Slawig, Thomas and Oschlies, Andreas},
  date = {2017-03-29},
  journaltitle = {Biogeosciences},
  volume = {14},
  number = {6},
  pages = {1647--1701},
  issn = {1726-4189},
  doi = {10.5194/bg-14-1647-2017},
  url = {https://bg.copernicus.org/articles/14/1647/2017/},
  abstract = {Abstract. To describe the underlying processes involved in oceanic plankton dynamics is crucial for the determination of energy and mass flux through an ecosystem and for the estimation of biogeochemical element cycling. Many planktonic ecosystem models were developed to resolve major processes so that flux estimates can be derived from numerical simulations. These results depend on the type and number of parameterizations incorporated as model equations. Furthermore, the values assigned to respective parameters specify a model's solution. Representative model results are those that can explain data; therefore, data assimilation methods are utilized to yield optimal estimates of parameter values while fitting model results to match data. Central difficulties are (1) planktonic ecosystem models are imperfect and (2) data are often too sparse to constrain all model parameters. In this review we explore how problems in parameter identification are approached in marine planktonic ecosystem modelling. We provide background information about model uncertainties and estimation methods, and how these are considered for assessing misfits between observations and model results. We explain differences in evaluating uncertainties in parameter estimation, thereby also discussing issues of parameter identifiability. Aspects of model complexity are addressed and we describe how results from cross-validation studies provide much insight in this respect. Moreover, approaches are discussed that consider time- and space-dependent parameter values. We further discuss the use of dynamical/statistical emulator approaches, and we elucidate issues of parameter identification in global biogeochemical models. Our review discloses many facets of parameter identification, as we found many commonalities between the objectives of different approaches, but scientific insight differed between studies. To learn more from results of planktonic ecosystem models we recommend finding a good balance in the level of sophistication between mechanistic modelling and statistical data assimilation treatment for parameter estimation.},
  keywords = {ecosystem-models}
}
@article{Schneider2017,
  title = {Earth {{System Modeling}} 2.0: {{A Blueprint}} for {{Models That Learn From Observations}} and {{Targeted High}}‐{{Resolution Simulations}}},
  author = {Schneider, Tapio and Lan, Shiwei and Stuart, Andrew and Teixeira, João},
  date = {2017-12-28},
  journaltitle = {Geophysical Research Letters},
  volume = {44},
  number = {24},
  eprint = {1709.00037},
  eprinttype = {arxiv},
  pages = {12,396--12,417},
  issn = {0094-8276},
  doi = {10.1002/2017GL076101},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/2017GL076101},
  abstract = {Climate projections continue to be marred by large uncertainties, which originate in processes that need to be parameterized, such as clouds, convection, and ecosystems. But rapid progress is now within reach. New computational tools and methods from data assimilation and machine learning make it possible to integrate global observations and local high-resolution simulations in an Earth system model (ESM) that systematically learns from both and quantifies uncertainties. Here we propose a blueprint for such an ESM. We outline how parameterization schemes can learn from global observations and targeted high-resolution simulations, for example, of clouds and convection, through matching low-order statistics between ESMs, observations, and high-resolution simulations. We illustrate learning algorithms for ESMs with a simple dynamical system that shares characteristics of the climate system; and we discuss the opportunities the proposed framework presents and the challenges that remain to realize it.},
  keywords = {climate,DL,inference,machinelearning,parameter-estimation,sciml}
}

@article{Toms2020,
  title = {Physically {{Interpretable Neural Networks}} for the {{Geosciences}}: {{Applications}} to {{Earth System Variability}}},
  author = {Toms, Benjamin A. and Barnes, Elizabeth A. and Ebert-Uphoff, Imme},
  date = {2020},
  journaltitle = {Journal of Advances in Modeling Earth Systems},
  volume = {12},
  number = {9},
  eprint = {1912.01752},
  eprinttype = {arxiv},
  pages = {1--20},
  issn = {19422466},
  doi = {10.1029/2019MS002002},
  abstract = {Neural networks have become increasingly prevalent within the geosciences, although a common limitation of their usage has been a lack of methods to interpret what the networks learn and how they make decisions. As such, neural networks have often been used within the geosciences to most accurately identify a desired output given a set of inputs, with the interpretation of what the network learns used as a secondary metric to ensure the network is making the right decision for the right reason. Neural network interpretation techniques have become more advanced in recent years, however, and we therefore propose that the ultimate objective of using a neural network can also be the interpretation of what the network has learned rather than the output itself. We show that the interpretation of neural networks can enable the discovery of scientifically meaningful connections within geoscientific data. In particular, we use two methods for neural network interpretation called backward optimization and layerwise relevance propagation, both of which project the decision pathways of a network back onto the original input dimensions. To the best of our knowledge, LRP has not yet been applied to geoscientific research, and we believe it has great potential in this area. We show how these interpretation techniques can be used to reliably infer scientifically meaningful information from neural networks by applying them to common climate patterns. These results suggest that combining interpretable neural networks with novel scientific hypotheses will open the door to many new avenues in neural network-related geoscience research.},
  keywords = {sciml}
}


@article{Yazdani2020,
  title = {Systems Biology Informed Deep Learning for Inferring Parameters and Hidden Dynamics},
  author = {Yazdani, Alireza and Lu, Lu and Raissi, Maziar and Karniadakis, George Em},
  editor = {Hatzimanikatis, Vassily},
  date = {2020-11-18},
  journaltitle = {PLOS Computational Biology},
  volume = {16},
  number = {11},
  eprint = {33206658},
  eprinttype = {pmid},
  pages = {e1007575},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007575},
  url = {http://dx.doi.org/10.1371/journal.pcbi.1007575},
  abstract = {Mathematical models of biological reactions at the system-level lead to a set of ordinary differential equations with many unknown parameters that need to be inferred using relatively few experimental measurements. Having a reliable and robust algorithm for parameter inference and prediction of the hidden dynamics has been one of the core subjects in systems biology, and is the focus of this study. We have developed a new systems-biology-informed deep learning algorithm that incorporates the system of ordinary differential equations into the neural networks. Enforcing these equations effectively adds constraints to the optimization procedure that manifests itself as an imposed structure on the observational data. Using few scattered and noisy measurements, we are able to infer the dynamics of unobserved species, external forcing, and the unknown model parameters. We have successfully tested the algorithm for three different benchmark problems.},
  isbn = {1111111111},
  keywords = {ai-ecology,bayesianinference,parameter-estimation}
}

@article{dormann2007,
  title = {Promising the Future? {{Global}} Change Projections of Species Distributions},
  shorttitle = {Promising the Future?},
  author = {Dormann, Carsten F.},
  date = {2007-09-03},
  journaltitle = {Basic and Applied Ecology},
  shortjournal = {Basic and Applied Ecology},
  volume = {8},
  number = {5},
  pages = {387--397},
  issn = {1439-1791},
  doi = {10.1016/j.baae.2006.11.001},
  url = {https://www.sciencedirect.com/science/article/pii/S143917910600106X},
  urldate = {2023-10-05},
  abstract = {Projections of species’ distribution under global change (climatic and environmental) are of great scientific and societal relevance. They rely on a proper understanding of how environmental drivers determine species occurrence patterns. This understanding is usually derived from an analysis of the species’ present distribution by statistical means (species distribution models). Projections based on species distribution models make several assumptions (such as constancy of limiting factors, no evolutionary adaptation to drivers, global dispersal), some of which are ecologically untenable. Also, methodological issues muddy the waters (e.g. spatial autocorrelation, collinearity of drivers). Here, I review the main shortcomings of species distribution models and species distribution projections, identify limits to their use and open a perspective on how to overcome some current obstacles. As a consequence, I caution biogeographers against making projections too light-heartedly and conservation ecologists and policy makers to be aware that there are several unresolved problems. Zusammenfassung Die Auswirkungen von Umweltveränderungen (Klima und Landnutzung) auf die zukünftige Verbreitung von Tier- und Pflanzenarten ist ein aktueller und gesellschaftlich relevanter Forschungsgegenstand. Solche Vorhersagen fußen auf einer sicheren Kenntnis der für die Verteilung relevanten Umweltfaktoren, gewonnen aus der statistischen Analyse der gegenwärtigen Verbreitung. Vorhersagen auf Grundlage einer Verbreitungsanalyse unterliegen verschiedenen Annahmen (z.B.: limitierende Faktoren bleiben limitierend; keine genetische Anpassung an veränderte Umweltbedingungen; keine Ausbreitungsbeschränkung), von denen einige ökologisch unhaltbar sind. Zudem gibt es eine Vielzahl statistischer Probleme (z.B.: räumliche Autokorrelation; Kollinearität von Umweltparametern). In diesem Beitrag stelle ich die wichtigsten Probleme von Verbreitungsanalysen und Verbreitungsvorhersagen vor, zeige die Grenzen dieser Methodik auf und weise auf Lösungsansätze hin. Schlussfolgerung dieser Erörterung ist, dass wir es uns mit Vorhersagen nicht zu leicht machen sollten, und dass Umweltschützer und Politiker sich der methodischen Unsicherheiten bewusst sein sollten.},
  keywords = {forecast,globalchangebiology,SDM}
}

@article{hartig2012,
  title = {Connecting Dynamic Vegetation Models to Data - an Inverse Perspective: {{Dynamic}} Vegetation Models - an Inverse Perspective},
  shorttitle = {Connecting Dynamic Vegetation Models to Data - an Inverse Perspective},
  author = {Hartig, Florian and Dyke, James and Hickler, Thomas and Higgins, Steven I. and O’Hara, Robert B. and Scheiter, Simon and Huth, Andreas},
  date = {2012-12},
  journaltitle = {Journal of Biogeography},
  shortjournal = {J. Biogeogr.},
  volume = {39},
  number = {12},
  pages = {2240--2252},
  issn = {03050270},
  doi = {10.1111/j.1365-2699.2012.02745.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1365-2699.2012.02745.x},
  urldate = {2022-11-30},
  abstract = {Dynamic vegetation models provide process-based explanations of the dynamics and the distribution of plant ecosystems. They offer significant advantages over static, correlative modelling approaches, particularly for ecosystems that are outside their equilibrium due to global change or climate change. A persistent problem, however, is their parameterization. Parameters and processes of dynamic vegetation models (DVMs) are traditionally determined independently of the model, while model outputs are compared to empirical data for validation and informal model comparison only. But field data for such independent estimates of parameters and processes are often difficult to obtain, and the desire to include better descriptions of processes such as biotic interactions, dispersal, phenotypic plasticity and evolution in future vegetation models aggravates limitations related to the current parameterization paradigm. In this paper, we discuss the use of Bayesian methods to bridge this gap. We explain how Bayesian methods allow direct estimates of parameters and processes, encoded in prior distributions, to be combined with inverse estimates, encoded in likelihood functions. The combination of direct and inverse estimation of parameters and processes allows a much wider range of vegetation data to be used simultaneously, including vegetation inventories, species traits, species distributions, remote sensing, eddy flux measurements and palaeorecords. The possible reduction of uncertainty regarding structure, parameters and predictions of DVMs may not only foster scientific progress, but will also increase the relevance of these models for policy advice.},
  langid = {english},
  keywords = {ecosystem-models,inference,vegetation-model}
}

@article{rasp2018,
  title = {Deep Learning to Represent Subgrid Processes in Climate Models},
  author = {Rasp, Stephan and Pritchard, Michael S. and Gentine, Pierre},
  date = {2018-09-25},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {39},
  pages = {9684--9689},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1810286115},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.1810286115},
  urldate = {2023-01-30},
  abstract = {The representation of nonlinear subgrid processes, especially clouds, has been a major source of uncertainty in climate models for decades. Cloud-resolving models better represent many of these processes and can now be run globally but only for short-term simulations of at most a few years because of computational limitations. Here we demonstrate that deep learning can be used to capture many advantages of cloud-resolving modeling at a fraction of the computational cost. We train a deep neural network to represent all atmospheric subgrid processes in a climate model by learning from a multiscale model in which convection is treated explicitly. The trained neural network then replaces the traditional subgrid parameterizations in a global general circulation model in which it freely interacts with the resolved dynamics and the surface-flux scheme. The prognostic multiyear simulations are stable and closely reproduce not only the mean climate of the cloud-resolving simulation but also key aspects of variability, including precipitation extremes and the equatorial wave spectrum. Furthermore, the neural network approximately conserves energy despite not being explicitly instructed to. Finally, we show that the neural network parameterization generalizes to new surface forcing patterns but struggles to cope with temperatures far outside its training manifold. Our results show the feasibility of using deep learning for climate model parameterization. In a broader context, we anticipate that data-driven Earth system model development could play a key role in reducing climate prediction uncertainty in the coming decade.},
  keywords = {climate,DL,machinelearning,sciml},
}
@article{Strouwen2022,
  title = {Robust Dynamic Experiments for the Precise Estimation of Respiration and Fermentation Parameters of Fruit and Vegetables},
  author = {Strouwen, Arno and Nicolaï, Bart M. and Goos, Peter},
  editor = {Mendes, Pedro},
  date = {2022-01-12},
  journaltitle = {PLOS Computational Biology},
  volume = {18},
  number = {1},
  eprint = {35020716},
  eprinttype = {pmid},
  pages = {e1009610},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009610},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1009610},
  abstract = {Dynamic models based on non-linear differential equations are increasingly being used in many biological applications. Highly informative dynamic experiments are valuable for the identification of these dynamic models. The storage of fresh fruit and vegetables is one such application where dynamic experimentation is gaining momentum. In this paper, we construct optimal O 2 and CO 2 gas input profiles to estimate the respiration and fermentation kinetics of pear fruit. The optimal input profiles, however, depend on the true values of the respiration and fermentation parameters. Locally optimal design of input profiles, which uses a single initial guess for the parameters, is the traditional method to deal with this issue. This method, however, is very sensitive to the initial values selected for the model parameters. Therefore, we present a robust experimental design approach that can handle uncertainty on the model parameters.},
  isbn = {1111111111},
  file = {/Users/victorboussange/Zotero/storage/FFR4YXT3/journal.pcbi.1009610.pdf}
}
@article{burnham2004,
  title = {Multimodel {{Inference}}},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  date = {2004-11-30},
  journaltitle = {Sociological Methods \& Research},
  volume = {33},
  number = {2},
  pages = {261--304},
  issn = {0049-1241},
  doi = {10.1177/0049124104268644},
  url = {http://journals.sagepub.com/doi/10.1177/0049124104268644},
  abstract = {The model selection literature has been generally poor at reflecting the deep foundations of the Akaike information criterion (AIC) and at making appropriate comparisons to the Bayesian information criterion (BIC). There is a clear philosophy, a sound criterion based in information theory, and a rigorous statistical foundation for AIC. AIC can be justified as Bayesian using a “savvy” prior on models that is a function of sample size and the number of model parameters. Furthermore, BIC can be derived as a non-Bayesian result. Therefore, arguments about using AIC versus BIC for model selection cannot be from a Bayes versus frequentist perspective. The philosophical context of what is assumed about reality, approximating models, and the intent of model-based inference should determine whether AIC or BIC is used. Various facets of such multimodel inference are presented here, particularly methods of model averaging.},
  keywords = {inference,model-selection,parameter-estimation},
  file = {/Users/victorboussange/Zotero/storage/26KG33J8/0049124104268644.pdf}
}
@book{Burnham2002,
  title = {Model {{Selection}} and {{Multimodel Inference}}},
  author = {Kenneth P. Burnham, David R. Anderson and {Model}},
  editor = {Burnham, Kenneth P. and Anderson, David R.},
  date = {2002},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/b97636},
  url = {http://link.springer.com/10.1007/b97636},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-α-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 Å for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  isbn = {978-0-387-95364-9},
  keywords = {inference,model-selection,parameter-estimation},
  file = {/Users/victorboussange/Zotero/storage/8FBJLAR9/Burnham-Anderson2002_Book_ModelSelectionAndMultimodelInf.pdf}
}
