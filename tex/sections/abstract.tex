The differentiable programming paradigm has become a central component of modern machine learning techniques. 
A long tradition of this paradigm exists in the context of scientific computing, in particular in partial differential equation-constrained, gradient-based optimization.
The recognition of the strong conceptual synergies between inverse methods and machine learning offers the opportunity to lay out a coherent framework applicable to both fields.
For models described by differential equations, the calculation of sensitivities and gradients requires careful algebraic and numeric manipulations of the underlying dynamical system.
Here, we provide a comprehensive review of existing techniques to compute gradients of numerical solutions of differential equation systems.
We first discuss the importance of gradients of solutions of ODEs in a variety of scientific domains, covering computational fluid dynamics, electromagnetism, geosciences, meteorology, oceanograpgy, climate science, flux inversion, glaciology, solid earth geophysics, biology and ecology, and quantum physics.
Second, we lay out the mathematical foundations of the different approaches. 
Finally, we discuss the computational consideration and solutions that exist in modern scientific software. 