The adjoint state method is another example of a discrete method that aims to find the gradient by solving an alternative system of linear equations, known as the \textit{adjoint equations}, at the same time that we solve the original system of linear equations defined by the numerical solver. 
These methods are extremely popular in optimal control theory in fluid dynamics, for example for the design of geometries for vehicles and airplanes that optimize performance \cite{Elliott_Peraire_1996, Giles_Pierce_2000}
This approach follows the discretize-optimize approach, meaning that we first discretize the system of continuous ODEs and then solve on top of these linear equations \cite{Giles_Pierce_2000}. 
Just as in the case of automatic differentiation, the set of adjoint equations can be solved in both forward and backward mode. 
% Just as in the case of automatic differentiation, the adjoint state method evaluates the gradient by moving forward in time and applying the chain rule sequentially over a discrete set of operations that dictate the updates by the numerical scheme for solving the differential equation. However, it does so by directly computing the gradient by solving a new system of equations.

The first step in order to derive the adjoint equation is to discretize the set of differential equations in \eqref{eq:original_ODE} into finite evaluations of the function $u(t; \theta)$. 
Given the set of timesteps $t_0, t_1, \ldots, t_N$, we evaluate the solution at $u_i = u(t_i; \theta)$. 
In the case of using an explicit numerical solver, these values will be constrained to satisfy a set of equations of the form 
\begin{equation}
    u_{i+1} = A_i (\theta) \, u_i + b_i
\end{equation}
with $A_i \in \R^{n \times n}$ a squared matrix defined by the numerical solver. 
If we call the super-vector $U = (u_1, u_2, \ldots, u_N) \in \R^{nN}$, we can combine all these equations in into one single system of linear equations 
\begin{equation}
    A(\theta) U 
    = 
    \begin{bmatrix}
        \I_{n \times n} & 0 &   &  & \\
        -A_1 & \I_{n \times n} & 0 &  &  \\
          & -A_2 & \I_{n \times n} & 0 &  \\
         &  &   & \ddots &   \\
         &  &  & -A_{N-1} & \I_{n \times n}
    \end{bmatrix}
    \begin{bmatrix}
        u_1 \\
        u_2 \\
        u_3 \\
        \vdots \\
        u_N
    \end{bmatrix}
    = 
    \begin{bmatrix}
        M_0 u_0 + b_0 \\
        b_1 \\
        b_2 \\
        \vdots \\
        b_{N-1}
    \end{bmatrix}
    = 
    b(\theta), 
\end{equation}
with $\I_{n \times n}$ the identity matrix of size $n \times n$.
It is usually convenient to write this system of linear equations in the residual form $G(U; \theta) = 0$, where $G(U; \theta) = A(\theta) U - b(\theta)$ is the residual between both sides of the equation. 
Different numerical schemes will lead to different design matrix $A(\theta)$ and vector $b(\theta)$, but ultimately every numerical method will lead to a system of linear equations with the form $G(U; \theta) = A(\theta) U - b(\theta) = 0$ after being discretized. 

We are interested in differentiating a function $h(U, \theta)$ constrained to satisfy the algebraic linear equation $G(U; \theta) = 0$.
Now,
\begin{equation}
    \frac{dh}{d\theta} = \frac{\partial h}{\partial \theta} + \frac{\partial h }{\partial U} \frac{\partial U}{\partial \theta},
    \label{eq:dhdtheta0}
\end{equation}
and also for the constraint $G(U; \theta)=0$ we can derive
\begin{equation}
    \frac{dG}{d\theta} 
    = 
    \frac{\partial G}{\partial \theta} 
    + 
    \frac{\partial G}{\partial U} \frac{\partial U}{\partial \theta}
    =
    0
\end{equation}
which is equivalent to 
\begin{equation}
    \frac{\partial U}{\partial \theta} 
    = 
    - \left( \frac{\partial G}{\partial U} \right)^{-1} \frac{\partial G}{\partial \theta}.
\end{equation}
If we replace this last expression into equation \eqref{eq:dhdtheta0}, we obtain
\begin{equation}
    \frac{dh}{d\theta} 
    =
    \frac{\partial h}{\partial \theta} - \frac{\partial h}{\partial U} \left( \frac{\partial G}{\partial U} \right)^{-1} \frac{\partial G}{\partial \theta}.
    \label{eq:dhdtheta}
\end{equation}
Now, let's define the adjoint $\lambda \in \R^{nN}$ as the solution of the linear system of equations 
\begin{equation}
    \left( \frac{\partial G}{\partial U}\right)^T \lambda =  \left( \frac{\partial h}{\partial U} \right)^T,
\end{equation}
that is,
\begin{equation}
    \lambda^T = \frac{\partial h}{\partial U} \left( \frac{\partial g}{\partial U} \right)^{-1}.
    \label{eq:def_adjoint}
\end{equation}
Finally, if we replace Equation \eqref{eq:def_adjoint} into \eqref{eq:dhdtheta}, we obtain 
\begin{equation}
    \frac{dh}{d\theta} 
    =
    \frac{\partial h}{\partial \theta} - \lambda^T \frac{\partial G}{\partial \theta}.
\end{equation}
The important trick to notice here is the rearrangement of the multiplicative terms involved in equation \eqref{eq:dhdtheta}. Computing the full Jacobian/sensitivity $\partial u / \partial \theta$ will be computationally expensive and involves the product of two matrices. However, we are not interested in the calculation of the Jacobian, but instead in the VJP given by $\frac{\partial h}{\partial U} \frac{\partial U}{\partial \theta}$. By rearranging these terms, we can make the same computation more efficient. 

\begin{example*}[Linear system]
Let's see this by considering the simple example of a linear system of equations. Suppose that the constraint $g(u, \theta)=0$ takes the form $A(\theta) u = b(\theta)$ \cite{Johnson}. In that case, we have
\begin{equation}
    \frac{\partial g}{\partial \theta} = \frac{\partial A }{\partial \theta} u - \frac{\partial b}{\partial \theta},
\end{equation}
so the gradient can be computed as 
\begin{equation}
    \frac{dh}{d\theta} = \frac{\partial h}{\partial \theta} - \lambda^T \left( \frac{\partial A }{\partial \theta} u - \frac{\partial b}{\partial \theta} \right)
    \label{eq:dhdtheta_linear}
\end{equation}
with $\lambda$ the solution of the linear system 
\begin{equation}
    A(\theta)^T \lambda = \frac{\partial h}{\partial u}^T.
\end{equation}
This is a linear system of equations with the same size of the original $Au = b$, but involving the adjoint matrix $A^T$. Computationally this also means that if we can solve the original system then we can also solve the adjoint (for example, with LU factorization $A=LU$ we have $A^T=U^TL^T$).
This example also allows us to see the improvement  in efficiency achieved by first computing the adjoint and then the full gradient. For a linear constraint, equation \eqref{eq:dhdtheta_linear} becomes
\begin{equation}
    \frac{dh}{d\theta} = \frac{\partial h}{\partial \theta} - 
    \underbrace{\frac{\partial h}{\partial u}}_{1 \times n}
    \underbrace{A^{-1}}_{n \times n} 
    \underbrace{\left( \frac{\partial A }{\partial \theta} u - \frac{\partial b}{\partial \theta} \right)}_{n \times p}.
    \label{eq:state_method_linear}
\end{equation}
Computing first the last product will cost $O(n^2p)$ to generate a $n \times p$ matrix. On the other side, if first we solve the first two terms in the product, this will cost $O(n)$ and them the product will be just $O(np)$. In order words, it is easy to compute the full gradient if we treat the last term in equation \eqref{eq:state_method_linear} as a VJP. 
\end{example*}

In order to compute the gradient of the full solution of the differential equation, we apply this method sequentially using the chain rule. One single step of the state method can be understood as the chain of operations $\theta \mapsto g \mapsto u \mapsto L$. This allows us to create adjoints for any primitive function $g$ (i.e. the numerical solver scheme) we want, and then incorporated it as a unit of any AD program. 