% Mention to higher order ODEs

\subsection{Partial differential equations}

% We could also link to PDE-constrained optimization and the adjoint method1 Andrew M. Bradley

% These techniques extend to time-dependent problems through the method-of-lines, where the problem is first discretized in space to produce a semi-discrete problem, which is then integrated in time using standard ODE solvers. 

Although we here consider the case of ODEs, that is, when the derivatives are just with respect to the time variable $t$, the ideas presented in this review can be extended to partial differential equations (PDEs) (when discretized via e.g. the method of lines \cite{ascher2008numerical}), and to differential algebraic equations (DAEs) \cite{hairer-solving-2}.
The same recipe used here to derive the continuous adjoint method for a system of ODEs can be employed to derive adjoint methods for PDEs \cite{Giles_Pierce_2000} and DAE \cite{Cao_Li_Petzold_2002}. 

Significant challenges remain, however, in the practical implementation of sensitivity methods for PDE and DAE systems. 
Discretized PDEs typically involve the solution of moderate to large systems of coupled (and possibly stiff) ODEs subject to some suitable boundary conditions. 
Explicit calculation of the Jacobian quickly becomes cumbersome and eventually intractable as the spatial dimension and resolution of the PDE increase.
PDEs are often also subject to additional time stepping constraints, such as the Courant-Fredrichs-Lewy condition \cite{courantPartialDifferenceEquations1967}, which may limit the maximum time step size and thus increase the number of time steps required to obtain a valid solution. 
This may limit the practicality of sensitivity methods that require the storage of a dense forward solution, such as reverse-mode AD and adjoint methods, an effect that can be mitigated by using checkpointing (see Sections \ref{section:checkpointing} and \ref{section:checkpointint-cont}).
However, the memory footprint for even moderate size PDE systems (e.g. $10^2$ to $10^3$ equations) over long time spans can still incur a large memory cost in cases where many checkpoints are required for stability in the reverse pass. 
This again can be mitigated by a multi-level checkpointing approach that enables checkpointing to either memory or to disk (see section XXX).

Another practical consideration when differentiating numerical PDE solvers arises from the way they are typically implemented. 
Due to the large size of the system, numerical calculations for PDEs are typically performed in-place, i.e. large memory buffers are often used to store intermediate calculations and system state thereby avoiding the need to repeatedly allocate large amounts of memory for each array operation. 
This can preclude the use of reverse AD implementations that do not support in-place mutation of arrays.

PDEs therefore remain some of the most challenging problems for computing sensitivities due to the frequent combination of a large number of discretized possibly stiff ODEs, with a large memory footprint. 
This makes it difficult to strike a balance between memory usage and computational performance. 
There are, however, numerous recent developments that have made solutions to these challenges more accessible. 
Automated sparsity detection \cite{gowdaSparsityProgrammingAutomated2019} and Newton-Krylov methods \cite{knollJacobianfreeNewtonKrylov2004,montoisonKrylovJlJulia2023} can drastically decrease both the time and space complexity of calculating JVPs or VJPs for large systems. 
Recent advances in applying AD to implicit functions \cite{blondelEfficientModularImplicit2022a}, i.e. functions which require the solution of a nonlinear system, also provide a promising path forward for many complex PDE and DAE problems that often involve multiple nested numerical solvers. 
Finally, some state-of-the-art AD tools such as Enzyme \cite{moses_Enzyme} are able to support both in-place modification of arrays as well as complex control flow, making them directly applicable to many high efficiency numerical codes for solving PDEs.

% TODO: more dicussion on solutions and recommendations; e.g. sparsity detection for large systems, checkpointing (already mentioned), combining parameter efficient reverse-mode AD with efficient mutation-supporting AD tools like Enzyme for the JVP calculation.

% TODO: more commnets on DAEs?

\subsection{Differential algebraic equations}

\subsection{Stochastic differential equations}

% Just a few sentences of what is different here. Probably we first need to introduce what they are and where they are used. 

% Check on paper: https://arxiv.org/pdf/2001.01328

\subsection{Chaotic systems}

% Integreate this paragraph in this section
% It is important to remark that adjoint methods can fail in chaotic systems \cite{Wang2012-chaos-adjoint}.
% Some works have shown that continuous adjoints can lead to unstable sensitivities \cite{Jensen_Nakshatrala_Tortorelli_2014}.
% In the more general case, discrete and continuous adjoint methods can give different computational results \cite{Sirkes_Tziperman_1997}.

% Intro: why we take this average quantities in chaotic system? Need to motivate this in a sentense.
All the sensitivity methods discussed in the previous sections encounter challenges and become less useful when applied to chaotic systems \cite{Wang2012-chaos-adjoint}.
To illustrate this, let us consider long-time-averaged quantities 
\begin{equation}\label{eq:long_time_averaged_quantities}
    \langle L(\theta) \rangle_T = \frac{1}{T} \int_0^T L(u(t), \theta) \, dt, 
\end{equation}
of chaotic systems, where $L(u(t), \theta)$ is the instantaneous objective and $u(t)$ denotes the state of the dynamical system at time $t$.
For ergodic dynamical systems, $\lim_{T\to\infty} \langle L(\theta) \rangle_T$ depends solely on the governing dynamical system and is independent of the specific choice of trajectory $u(t)$. 
In particular, $\lim_{T\to\infty} \langle L(\theta) \rangle_T$ does not depend on the initial condition. 
Under the assumption of uniform hyperbolic systems, it is possible to derive closed-form expressions and differentiability conditions for $ \langle L(\theta) \rangle_T$ \cite{ruelle1997differentiation,ruelle2009review}.
However, computing derivatives using numerical methods of statistical quantities of the form \eqref{eq:long_time_averaged_quantities} with respect to the parameter $\theta$ in chaotic dynamical systems remains challenging due to the \textit{butterfly effect}, i.e. small changes in the initial state or parameter can result in large differences in a later state \cite{Lorenz.1963}.
As a consequence, the solutions of the forward sensitivity equations and adjoint differential equation blow up (exponentially fast) instead of converging to the actual derivative.
To address these issues, various modifications and methods have been proposed, including approaches based on ensemble averages~\cite{lea2000sensitivity, eyink2004ruelle}, the Fokker-Planck equation~\cite{thuburn2005climate, blonigan2014probability}, the fluctuation-dissipation theorem~\cite{leith1975climate, abramov2007blended, abramov2008new}, shadowing lemma~\cite{wang2013forward, wang2014least, wang2014convergence, ni2017sensitivity, blonigan2017adjoint, blonigan2018multiple, ni2019adjoint, ni2019sensitivity}, and modifications of Ruelle's formula~\cite{chandramoorthy2022efficient, ni2020fast}.

In Julia, this is implemented in the sensitivity method \texttt{AdjointLSS} and \texttt{NILSS}. % More explanation of what these do
Standard derivative approximations are inappropriate for such systems and will not give convergent estimates.
% This includes AD of a solver.