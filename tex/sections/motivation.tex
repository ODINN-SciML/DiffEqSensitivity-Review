% Add some use cases 
% - Parameter estimation 
% - State methods

\subsection{On the importance of differentiable programming}

Scientific models have long been based on domain-specific equations, often represented as differential equations, involving the use of numerical methods to solve them. Most of the fundamental advances in the physical sciences during the last century were achieved with the combination of complex mathematical theories and a reduced amount of observations to validate them. Nonetheless, in the 21st century, with the unstoppable wave of data flooding all scientific domains, progress with such traditional methods has become more complex. The powers of mechanistic models pail at the sheer size of the huge datasets currently available, and their rigid structures become problematic. 

Alternatively, the field of statistics has experienced a boom following the massive growth of data, signaling the era of data science and machine learning. With the advent of new advanced machine learning methods, it is possible to learn and capture extremely complex nonlinear patterns and information hidden in huge datasets. Such methods have revolutionised almost every field in industry and academia, and we can hardly spend a day without using this technology operating under the hood of many of our everyday routines. Machine learning models can be seen as the opposite of mechanistic models: they are flexible, data-driven and they do not necessarily respect domain-specific constraints.

At first sight, these two modelling philosophies can be seen as antagonistic, and this is more or less the way they have evolved in the last decades \cite{zdeborova_understanding_2020}. On the one hand, domain scientists have often struggled to adopt these novel machine learning methods, judging them as opaque black boxes, unreliable and not respecting domain established knowledge. On the other hand, the field of machine learning has mainly been developed around huge neural network architectures with millions of parameters. Such supermodels have indeed an impressive amount of predictive power, but their size renders them impossible to interpret and they have an extreme dependency on data to make accurate predictions. However, in the last years there has been an increasing interest in making mechanistic models more flexible, as well as introducing domain-specific or physical constraints and interpretability in machine learning models. If both modelling approaches have different strengths, why not combine them and attempt to have the best of both worlds?

They key to achieve this is differentiable programming, i.e. being able to compute derivatives/gradients of any computer program describing a scientific model. While the computation of gradients of differential equations and neural networks has been around for many decades, it has mostly been achieved independently of each other. The differentiation of hybrid models comprising data-driven models (e.g. neural networks) with differential equations poses complex technical problems, which are only starting to be explored in recent years \cite{ma_comparison_2021}. Being able to accurately estimate model parameters, ranging from a few ones in classic inversion problems to millions of them in large neural networks, opens many new possibilities. Differentiable programming has the potential to revolutionize the way we approach and design scientific models, and even the way we discover governing laws from data. 

\subsection{Domain-specific applications}

Differential equations can be used to describe a large variety of dynamical systems, while data-driven models like neural networks have been demonstrated to act as universal approximators, virtually learning any possible function if enough data is available \cite{gorban_1998}. This combined flexibility can be exploited by many different domain-specific problems to tailor modelling needs to both dynamics and data characteristics.

\subsubsection{Geosciences}

In geosciences, partial differential equations (PDEs) are often used to simulate fluid dynamics, describing geophysical properties of many Earth systems, such as the atmosphere, oceans or glaciers. In such models, calibrating model parameters is extremely challenging, due to datasets being sparse in both space and time and noisy. Moreover, many existing mechanistic models can only partially describe observations, with many detailed physical processes being ignored or badly parametrized. The use of differentiable programming, combining PDEs and data-driven models (i.e. Universal Differential Equations) can add flexibility to mechanistic models in order to incorporate new governing laws from data \cite{rackauckas2020universal}.

Glaciers act as slow fluids, flowing down-slope through the effects of gravity, and the understanding of their rheological properties (e.g. internal deformation or sliding at their beds) is key to understanding their contribution to water resources and sea-level rise \cite{cuffey_physics_2010}. These rheological processes and their dependency on key environmental variables, such as the local climate or topography, are still not well understood. 

