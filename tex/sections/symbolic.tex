In symbolic differentiation, functions are represented algebraically instead of algorithmically, which is why many symbolic differentiation tools are included inside computer algebra systems (CAS) \cite{Symbolics_jl_2022}. 
Instead of numerically evaluating the final value of a derivative, symbolic systems assign variable names, expressions, operations, and literals to \textit{algebraic} objects. 
For example, the relation $y = x^2$ is interpreted as expression with two variables, $x$ and $y$, and the symbolic system generates the derivative $y' = 2 \times x$ with $2$ a numeric literal, $\times$ a binary operation, and $x$ the same variable assignment as in the original expression.
When the function to differentiate is large, symbolic differentiation can lead to \textit{expression swell}, that is, exponentially large or complex symbolic expressions \cite{Baydin_Pearlmutter_Radul_Siskind_2015}.
Simplification routines implemented in CAS may however reduce the size and complexity of algebraic expressions by finding common sub-expressions.  
This can make symbolic differentiation very efficient when computing derivatives multiple times and for different input values \cite{DÃ¼rrbaum_Klier_Hahn_2002}. 

The general issue with symbolic differentiation is expression swell, i.e. the fact that the size of a derivative expression can be much larger than the original expression. One way to visualize this swell is to note that the product rule grows and expression of $f(x)g(x)$ into two expressions, one differentiating each component, and thus the composition of many functions leads to a large derivative expression. Automatic differentiation avoids the expression swell by always eagerly calculating the derivative of a given expression around a point, never representing the general derivative but only at the values obtained by the forward pass. This eager evaluation of the derivative around a given point forces the computation into the Jacobian-vector product (column-by-column) or vector-Jacobian product (row-by-row) form as a way to continually pass forward/reverse the current state. Meanwhile, symbolic differentiation can represent the complete derivative expression and thus avoid being forced into a given computation order, but at the memory cost of having to represent larger expressions.

However with this in mind it is important to acknowledge the close relationship between AD and symbolic differentiation.
Automatic differentiation uses symbolic differentiation in its definition of primitives which are then chained together in a specific way to form vector-Jacobian products and Jacobian-vector products. 
Forward mode automatic differentiation can be expressed as a form of symbolic differentiation with a specific choice of common subexpression elimination, i.e. forward mode can be expressed as a symbolic differentiation with a specific choice of how to accumulate the intermediate calculations so that expression growth can be avoided \cite{juedes1991taxonomy, Elliott_2018, Laue2020}.
However, general symbolic differentiation can have many other choices for the differentiation order, and does not in general require computation using the vector-Jacobian products or Jacobian-vector products \cite{Baydin_Pearlmutter_Radul_Siskind_2015}. This is apparent for example when computing sparse Jacobians, where generally symbolic differentiation computes entries element-by-element while forward mode automatic differentiation computes the matrix column-by-column and reverse mode computes row-by-row. 

Generally automatic differentiation is recommended due to its generality on programs and the lack of potential memory issues by avoiding expression swell, though there are some situations where symbolic differentiation may be appropriate. For example, there are certain sparsity patterns by which even sparse automatic differentiation requires computing the full Jacobian via all columns/rows, while computing the sparse Jacobian element-by-element only requires computing the non-zero elements.
